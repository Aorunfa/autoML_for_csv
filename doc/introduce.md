
# 自动化结构化数据机器学习项目介绍
&emsp;&emsp;该项目主要面向结构化数据进行有监督学习的场景，主要目的是快速进行特征挖掘，特征筛选，特征建模并保存或载入相关建模结果。为此，项目主要开发了三个模块:
1. 模块AutoPlot主要针对特征探索过程的可视化，快速完成相关特征的可视化分析，特征探索
2. 模块AutoFeature主要针对特征组冗余过滤，快速完成关键特征组的确定
3. 模块AutoModel主要针对建模及集成寻优，快速完成模型选型与集成方式选择  
**以下将简单介绍每个模块的使用方式和一些关键代码。**

-----

# 算法1：auto_feature 自动特征筛选算法介绍
## 一.介绍
&emsp;&emsp;该自动特征筛选算法适用于结构化数据的监督学习场景，对构建的大量特征进行自动过滤，保留与标签较为相关的特征组合， 
减小特征冗余，帮助开发人员快速确定重要特征组，提高建模的效率和效果。  
该算法方案包括三种常用特征筛选的方法：
1. 过滤式：根据某个指标，判断特征与标签的相关性或分布独立性，对于小于阈值的指标进行过滤；进一步，判断特征之间的相关性或分布独立性，对大于阈值的特征组合，只保留与标签最相关的一个特征。  
2. 嵌套式：将特征组输入多个评分模型，获得每个模型输出的特征重要性，并对所有模型结果进行加权得到最终的特征重要评分，保留topN的特征组合。  
3. 包裹式：选择评分基模型，从一个特征开始，寻找能够使得模型预测效果最大的那一个特征加入特征池，每个阶段基于特征池搜索新的一个最优特征入池，直到到达目标数量。**注意该方式只能保证输出的特征组合是较优的，非全局最优组合**。

## 二.使用方式
### 2.1 数据准备
&emsp;&emsp;在运行算法前，需要对原始特征进行必要的数据清洗，如空值处理、异常值处理、字符数据转换等，并进行足够的特征工程。  
&emsp;&emsp;需要注意的是，算法能够处理回归问题的特征过滤以及二分类问题的特征过滤，对于多分类问题，在一些评估指标上尚不能实现自动化处理。以下展示示例数据sample.csv数据集里的基本数据情况。
   
### 2.2 运行内置方法

1. 实例化。根据问题指定必要的参数，必须要指定的是*fit_type*参数，若是回归问题则传入*regression*，分类问题则传入*classification*。其余参数含义参考注释，默认值可以满足大多数使用场景。

2. 过滤式筛选。调用实例.filter_corr(**params)方法即可，入参为数据集dataframe，数值特征列名list，分类特征列list，以及标签列名str，返回对应的过滤数据集，数值特征列和分类特征列。  

3. 嵌套式筛选。调用实例.filter_nesting(**params)方法，入参与过滤式的形式相似，包括数据集dataframe，特征列名list(包含数值特征或分类特征)，以及标签列名str，返回对应重要性排名在top_N的特征列list。  
    
4. 包裹式筛选。调用实例.filter_wrapping(**params)方法，入参与嵌套式相同，包括数据集dataframe，特征列名list(包含数值特征或分类特征)，以及标签列名str，同时指定评价基模型base_model，默认为cart树模型，以及要寻找的最大特征组数量group_n，默认为-1，对应为输入列名的数量，即不做限制。  
算法依次从一个特征数量开始，逐步加入新特征，每次找到能使评分模型最优的特征加入特征池。最后返回在给定特征数量group_n之内，使得评分基模型效果最好的特征组列名list。  


## 三.附录
### 3.1过滤式评估指标
&emsp;&emsp;过滤式计算指标包括两类，第一类为皮尔森相关系数，用于度量数值变量与数值标签（回归问题）、数值变量之间的相关性，**算法保留与数值标签相关性大于阈值的特征，过滤特征间相关性大于阈值的特征，保留其中与标签最相关的特征**；
第二类为卡方检验p值或互信息数值，见`_indpendent_test()`方法，用于度量分类标签（分类问题）与分类特征、数值特征的分布独立性，或用于度量数值标签（回归问题）与分类特征的分布独立性。**需要注意的是，在调用该方法时，需要对数值数据进行离散化分箱，保证结果的准确性**。


### 3.2嵌套式评分模型与参数空间
&emsp;&emsp;算法通过`_set_models()`内置了多种常见的评分基模型，包括cart Tree、xgboost、lightGBM、catboost，回归问题增加lasso回归，分类问题增加带l1正则化的logistic回归。
同时，基于评分基模型，通过`_set_params()`设置了对应模型的超参空间，使用者可以依据实际需求重写这两个方法。

### 3.3超参搜索器
&emsp;&emsp;超参搜索器主要用于搜索评分基模型最或较优超参组合，算法内置了三种算子：网格搜索、随机搜索、贝叶斯搜索。三者各有优劣。  
&emsp;&emsp;网格搜索暴力遍历参数组合，牺牲效率换取最好的效果；随机搜索根据一定的随机性，随机抽取参数组合，迭代至最大的次数，效率最快但效果可能是最差的；贝叶斯搜索主要基于已有的参数组合效果，以一定的条件分布抽取新的参数组合，兼顾效率与效果。
算法通过`_set_seacher()`进行设置，默认使用网格搜索。

### 3.4内置评价指标
&emsp;&emsp;算法分别内置了回归和分类问题的模型效果评估指标，主要用于交叉验证和重要性权值计算。  
&emsp;&emsp;`_set_metrics()`方法用于初始化评分指标字典，`_metric_fun()`方法用于根据参数`self.fit_type、self.fit_metric`调用评分字典，输出评分数值。  
&emsp;&emsp;**需要注意的是，当fit_metric为None时，回归问题默认评价指标为r2，分类问题为accuracy**。

----

# 算法2：auto_feature 自动化建模算法介绍
## 一.介绍
&emsp;&emsp;该自动建模算法适用于结构化数据的监督学习场景，对给定的特征组，快速训练多个不同的基模型，并基于基模型的结果，自动寻找最优的集成路径，实现快进行模型选型、集成方法选择，提高建模效率。  
该算法主要包括三个模块：
1. 基模型超参搜索与训练  
2. 基模型结果最优集成路径搜索  
3. 最后模型的预测，保存预加载预训练模型

## 二.使用方式

### 2.1 数据准备
&emsp;&emsp;在运行算法前，需要对原始数据完成数据清洗、数据转换、特征工程、特征过滤，得到最终的关键特征组。  
&emsp;&emsp;与auto_feature相同，目前算法能够处理回归问题以及二分类问题的自动建模，暂不支持对多分类问题的自动化处理

### 2.2 运行内置方法
1. 实例化。根据问题指定必要的参数，必须要指定的是*fit_type*参数，若是回归问题则传入*regression*，分类问题则传入*classification*。
其余参数含义参考注释，默认值可以满足大多数使用场景。根据*sample.csv*数据可以进行该实例化：  
`automodel = AutoModel(fit_type='classification', fit_metric='rec_pre')`  
表示场景为分类问题，评价指标选择racall与precision的复合指标

2. 模型训练与集成。调用实例automodel.fit(**params)方法即可。入参为数据集dataframe，特征列名list，以及标签列名str。

3. 结果预测。调用实例automodel.predict(**params)方法。输入参数为特征数据，可以是dataframe格式或者是np.array格式，将返回模型的最终预测结果，若存在最优集成路径，则返回多个模型的最优集成结果。

4. 模型保存与加载。运行`automodel.save_model(save_path)`保存训练好的最优模型，并通过`load_model(save_path)`进行模型加载。
path默认为None，将保存至或加载来自`./checkpoint`的模型文件。包括最优模型，或最优集成路径的基模型、相关权重、新的集成模型等等。

## 三.附录：模型集成方法说明
### 3.1 voting
&emsp;&emsp;算法内置基模型包含了单个基础模型以及boost、bagging相关的集成学习模型，对于这些模型的结果，设计了软硬投票的方式进行集成。  
&emsp;&emsp;软投票主要根据基模型在测试集上的评价指标进行平方归一化作为权值，或设置权值全为1，对基模型的结果进行加权，适用于回归与分类问题。硬投票主要针对分类问题，按照少数服从多数原则取基模型结果中出现最多的标签最为最终预测结果。

### 3.2 stacking
&emsp;&emsp;stacking的集成方式需要以基模型的预测结果作为特征重新训练新的分类或回归模型，为了降低过拟合风险，
算法预设了结构尽简单的模型，如回归采用lasso或浅层cart树(<=3层)，分类采用logit或浅层cart树。

### 3.3 集成路径选择
&emsp;&emsp;对于集成路径的选择，主要在验证集上筛选效果最好集成方法和最好的基模型，若`最好集成方法评价指标 > 最好基模型评价指标`则得到有效的集成方法，与基模型一起作为最优模型总成，否则最优模型为效果最好的基模型。

---